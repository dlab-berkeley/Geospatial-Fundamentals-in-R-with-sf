---
title: "Geospatial Fundamentals in R, Part 3: Raster Data"
author: "Patty Frontiera and Drew Hart, UC Berkeley D-Lab"
date: "Dec 2021"
output: #pdf_document
  ioslides_presentation:
    widescreen: true
    smaller: true
editor_options: 
  chunk_output_type: console
always_allow_html: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part III Prep

0. This workshop assumes you have R and RSTudio installed on your computer.

1. Open the repo at <https://github.com/dlab-berkeley/R-Geospatial-Fundamentals>
    - Download and unzip the zip file
    - Take note of where the folder is located

2. Locate the file `Geospatial-Fundamentals-in-R-with-sf.Rproj` in the folder and double-click on it. This will launch RStudio and with your `working directory` set to the folder containing these workshop files.

3. Check out the list of workshop files in the RSTUDIO `files panel` in the bottom-right of the RStudio interface. Navigate to the `docs` folder to see the tutorial docs. Double-click on `09_Raster_Data.Rmd` to open that file in RStudio.

4. Install the required libraries in RStudio, if you do not have them already

```{r, eval=F}
our_packages<- c("ggplot2", "sf", "tmap", "raster")
for (i in our_packages) {
  if ( i %in% rownames(installed.packages()) == FALSE) {
    install.packages(i)
  }
}
```


## Part III Overview

Introductions: me, you, the D-Lab, the workshop series

Review basic raster concepts

Read in some vector data and new raster data

Make some raster and combined raster-vector maps

Run some raster and raster-vector operations and analyses

## R Packages for working with Geospatial Data

### Old favorites

- `sp` for vector data
- `raster` for raster data

The `raster` package depends on `sp` for vector-raster operations.

### New packages:

- `sf` not so new anymore, the new default for vector data

- `terra` depends on the `sf` for vector-raster operations.

See this nice chart from the online book [Geocomputation with R](https://geocompr.robinlovelace.net) <https://geocompr.robinlovelace.net/figures/01-cranlogs.png>


## R Spatial Libraries

Let's load the libraries we will use

```{r, message=F, warning=F}
library(sf)     # simple features objects and methods
library(tmap)   # mapping spatial objects
library(raster) # reading in and operating on rasters
library(here)   # build paths from folder with .rproj file
```
 
## Set your working directory

A common practice for any coding script is to set your working directory to point to the folder in which the files you will be working with reside. In R, you would use the command `setwd` to set your working directory to the location of the tutorial files.

For example:

```{r, eval=FALSE}
my_folder = "~/Documents/repos/R-Geospatial-Fundamentals"
setwd(my_folder)
```

Alternately, you can use the `here()` function from the `here` package to build file paths that start at the `project directory`, as defined by the location of the `Rproj file`.  This method is the preferred way of setting the working directory in R and less error prone.

# Load some files from Parts I and II

We are going to start by using the `sf` library to load some `vector` point and polygon data for San Francisco that we used in part 1 & 2 of this workshop.

## SF Census Tracts

Read in the data from an ESRI shapefile to an `sf` spatial object with the function
`st_read`.
```{r}
# read the 'sftracts_wpop' shapefile
SFtracts_NAD83 <- st_read(here("notebook_data",
                         "part_3", 
                         "sftracts_wpop.shp"))

# Take a look
head(SFtracts_NAD83)
```

## Take a look at the CRS

Coordinate reference system details
```{r}
# get CRS details
st_crs(SFtracts_NAD83)
```

## SF Properties 2015

Read in property point data from a CSV file.

```{r}
# read from CSV file
SFhomes <- read.csv(here("notebook_data",
                         "part_3",
                         "sf_properties.csv"), 
                    stringsAsFactors = FALSE)

# subset the data because it is too much
SFhomes15 <- subset(SFhomes, as.numeric(SalesYear) == 2015)

# convert it to an `sf` object
SFhomes15_WGS84 <- st_as_sf(SFhomes15, 
                         coords = c('lon', 'lat'),
                         crs = 4326)
```

## Do the CRSs match?

```{r}
#take a look at the CRS details
st_crs(SFhomes15_WGS84)

# Or the shorter proj4string
st_crs(SFhomes15_WGS84)$proj4string

```

## CRS transformation of sf Objects

We can use the `sf::st_transform` function to reproject the `SFhomes15_WGS84` data to match that of the SFtracts_NAD83 or (vice versa).

- NOTE: We're overwriting the previous SFhomes15_sf object here!
- This is fine to do if we want, but we should always beware.
```{r}
# transform CRS and output a new object, overwriting old one
SFhomes15_NAD83 <- st_transform(SFhomes15_WGS84, st_crs(SFtracts_NAD83))

# Check projection equality
st_crs(SFhomes15_NAD83) == st_crs(SFtracts_NAD83)
```

## Make a quick plot of the two NAD83 sf spatial dataframes

```{r}
plot(SFtracts_NAD83$geometry)
plot(SFhomes15_NAD83$geometry, add=T, col="red")
```

## Challenge 1

In the code cell below
- transform SFtracts_NAD83 to WGS84 and name it SFtracts_WGS84
- take a look at the CRS info in the new
- Plot the WGS84 homes on top of the transformed SF tracts
```{r}
# YOUR CODE HERE
# transform SFtracts_NAD83 to WGS84
# SFtracts_WGS84 <- 

# Take a look at the crs
#Plot the WGS84 homes on top of the transformed SF tracts
```

## NAD27 vs NAD83 vs WGS84

WGS84 is a geographic CRS (lon/lat) optimized for the globe. It is the default!

NAD83 is a geographic CRS optimized for North America. It's best for USA data.

NAD27 is old and inaccurate! Don't use it.
```{r}
# Make sure we have the tract data from previous challenge!
SFtracts_WGS84 <- st_transform(SFtracts_NAD83, st_crs(SFhomes15_WGS84))
SFtracts_NAD27 <- st_transform(SFtracts_NAD83, 4267)

plot(SFtracts_WGS84$geometry, border="black")
plot(SFtracts_NAD83$geometry, border="green", add=T)
plot(SFtracts_NAD27$geometry, border="red", add=T)
```

# Section 1: Raster Data in R

## Read in a Raster

Use the fabulous `raster` package to read in a DEM

```{r}
# Reading in and plotting raster files

#read in a Bay Area DEM (Digital Elevation Model)
#(from http://www.webgis.com/terr_pages/CA/dem1/sanfrancisco.html)
DEM <- raster(here("notebook_data",
                   "part_3",
                   "san_francisco-e.DEM"))
```

## Plot it

Make a quick map of the data to check it out
```{r}
#plot it
plot(DEM)
```

## Explore the Structure

To see a summary of the structure and content of a `RasterLayer` object,
we can just enter the object's name.

```{r}
DEM
```
You can view more detail in the RStudio Environment panel.

## Explore the Structure

A raster should really just be a matrix of data, with metadata specifying
it the correct location on the Earth's surface, right?

In a `raster` object, the data and metadata will all be saved in their own
'slots', which are indexed by '@' rather than '$'.

('Slots' are components used to organize 'S4' objects. 'S4' is a data-type commonly
used by third-party packages to define their own special data structures.)

## Explore the Structure

Here's some of the important metadata.

```{r}
DEM@extent
DEM@crs
DEM@ncols
DEM@nrows
dim(DEM)
```

## Explore the Structure

And notice that the `DEM` object is indeed an 'S4' object.

```{r}
class(DEM)
typeof(DEM)
```

## Explore the Structure

Note that a `raster` object's structural organization and string-representation (the bit that is printed to the screen when you call the variable's name) are fundamentally different
from those of `sf` objects.  We can explore that in the Environment panel.


## Explore the Structure

For example, a `RasterLayer` has information on the resolution.

```{r}
DEM
```

## Explore the Structure

What does the resolution mean?

```{r}
res(DEM)
(DEM@extent@xmax - DEM@extent@xmin) / DEM@ncols
(DEM@extent@ymax - DEM@extent@ymin) / DEM@nrows
DEM

```
It's the cell-size! That is, the real-world distance of the x and y sides of
each cell (i.e. pixel) in our `RasterLayer`, expressed in the distance units
of the object (as determined by its projection). *What are those distance units?*

## A Note about Distance units

Are a component of the CRS.

If you want meters or feet you need to transform (or reproject) the raster to a projected 2D CRS that uses those units.

For example, UTM zone 10N, NAD83 (epsg code = 26911) is a widely used projected CRS for Northern CA spatial data analysis.

We will practice `reprojecting` rasters in just a little bit! 

## Explore the Structure

As for our matrix of data, it should live somewhere inside the `@data` slot, right?

```{r}
str(DEM@data)
```

## Explore the Structure

There's a bunch of stuff there. Let's take a look at the `@data@values` slot...

```{r}
DEM@data@values
```
## Explore the Structure

What happened there? How can our data be `logical(0)`?
Where's our data?

```{r}
DEM@data@inmemory
DEM@data@fromdisk
```

It appears our data was not all read into memory. Instead, our `RasterLayer` object
contains a pointer to where that data is held on disk (to save computer memory).

## Explore the Structure

How do we see the values, then?

Well, we can still subset the values, using two-dimensional `bracket` subsetting notation, just
as we'd expect for a matrix.

```{r}
DEM[1:4, 1:4] # return the values in rows 1-4 and cols 1-4
DEM[1,4]      # return the value in the cell at row 1, col 4
```
And we'll get back a vector of the values from that subsetted matrix, unfolded.

## Explore the Structure

We can even subset the entire thing, getting back all of the values.

```{r}
DEM[,]
```

## Explore the Structure

And we could even then turn that vector back into a matrix of the proper dimensions.

```{r}
#coerce a subset of the data values to a matrix, 
# with the appropriate number of rows and columns
matrix(DEM[1:4,1:4], ncol = 4, byrow = TRUE)

#coerce our whole raster data values to a matrix, 
# with the appropriate number of rows and cols
matrix(DEM[,], ncol = ncol(DEM), byrow = TRUE)
```

So, our `RasterLayer` object in many ways behaves like a `matrix`, 
much as a `sf` spatial dataframe object behaves like a `data.frame`.

## Explore the Structure

Can we create a new `RasterLayer` object from a matrix?

```{r}
test = raster(matrix(DEM[,], ncol = ncol(DEM), byrow = TRUE))
test
```

We do get a new `RasterLayer`! However, notice that it has no
`crs` defined, and thus it has an incorrect extent and resolution.

## Explore the Structure

You can imagine that you could then use
the DEM object's information to assign the new `RasterLayer` its appropriate metadata

- We did a similar operation above with the unprojected point `SFhomes` data that we read in 
from a CSV and coerced to an `sf` object. 

- We then used the `SFtracts` data, which has a defined `crs` to define the `crs` 
of the SFhomes spatial object.

BUT, it is easier than that...

## Explore the Structure

Our subsetting operation can actually take a `drop = FALSE` argument!

```{r}
DEM[1:5, 1:5]  # Bracket subsetting returns a vector

DEM[1:5, 1:5, drop = FALSE]  #add drop=False and what do you get?

```

And this gives us back a new RasterLayer object! (i.e. it doesn't drop the spatial)

In essence, this makes the subsetting operation more or less like a basic **clipping** function.


## Explore the Structure

Check it out...


```{r}
# go big to go home
test = DEM[1:500, 1:500, drop = FALSE]
plot(test)

# or
test = DEM[200:375, 525:800, drop = FALSE]
plot(test)

```

## Explore the Structure

And now what does the `@data@values` slot look like in our new object now?

```{r}
test@data@values
```

## Explore the Structure

That makes sense, because our test object didn't come from a file, so R
didn't leave its data on disk.

```{r}
test@data@inmemory
test@data@fromdisk
```

# Explore the data values

Descriptive raster statistics are called global raster operations. 

```{r}
# Quick summary stats
summary(DEM)

summary(DEM[,])

freq(DEM)

maxValue(DEM)
minValue(DEM)

res(DEM)
```


## Plot Data Values

Histogram is a great way to view distribution of data.

```{r}
hist(DEM[,],
     main = "Distribution of elevation values",
     xlab = "Elevation (meters)", ylab = "Frequency",
     col = "springgreen")
```

# Read Raster into Memory

If you have a small raster and/or lots of memory...

```{r}
# proceed with caution!
DEM2 <- readAll(DEM)

inMemory(DEM)
inMemory(DEM2)

hist(DEM,
     main = "Distribution of elevation values",
     xlab = "Elevation (meters)", ylab = "Frequency",
     col = "springgreen")
```

## CRS Transformations

Check the CRS (aka projection) of the DEM raster data.

Transform (or reproject) the CRS of the SF tracts vector data to match it.

We can transform the CRS of an sf object with `sf::st_transform`

```{r}
#check out its CRS
st_crs(DEM)

#or just its proj4string
proj4string(DEM)

# Reproject tracts to our DEM projection
SFtracts_NAD27 = st_transform(SFtracts_NAD83, st_crs(DEM))
st_crs(SFtracts_NAD27)
```

## Plot Raster and a Vector objects

Plot the DEM with the SF Tracts overlayed

```{r}
# Why do we set the value for ext?
plot(DEM, ext=extent(SFtracts_NAD27))

# Overlay the tracts
plot(SFtracts_NAD27$geometry, add=T)
```

## CRS Transformations

Above, we reprojected the vector sf object SFtracts to a new object
with the same CRS as the DEM raster.

Similarly, you can reproject the DEM with `raster::projectRaster`

- Note, the syntax is similar to `sf::st_transform`

```{r, error=T}
#Transform the CRS 
DEM_NAD83 = projectRaster(DEM, projectExtent(DEM, st_crs(SFtracts_NAD83)))

```

## CRS Transformations

Oops! What went wrong?

That's not a very informative error message...

Let's read the docs!

```{r, eval=F}
?projectRaster
```

## CRS Transformations

Looks like projectRaster requires the `crs` argument to be an object
of type (uppercase) 'CRS' class".  

Is it?

```{r}
class(st_crs(SFtracts_NAD83))
```

## CRS Transformations

We need to be careful when working between the `raster` and `sf` packages, because
`raster` is an older package and still depends on `sp`.

This (lowercase) `crs` class is defined by the `sf` package and it is returned by `sf::st_crs(SFtracts_NAD83)` because SFtracts_NAD83 is an `sf` object. Picky!

This (uppercase) `CRS` class is defined by the `sp/raster` package and is used to transform the CRS of a raster or sp object.

However, we can actually just extract the `proj4string` from our sf crs-class object and use that as our argument instead!


```{r}
#Transform the CRS 

# Check proj4string
st_crs(SFtracts_NAD83)$proj4string

# Use it to reproject the DEM
DEM_NAD83 = projectRaster(DEM, projectExtent(DEM, st_crs(SFtracts_NAD83)$proj4string))

# plot it
plot(DEM_NAD83, ext=extent(SFtracts_NAD83))
plot(SFtracts_NAD83$geometry, col=NA, add=T)
```

## CRS Transformations

Now,  we can check equivalence of the CRSs

```{r}
# Compare the CRS of these objects using sf::st_crs

# NAD27 (epsg = 4267)
st_crs(SFtracts_NAD27) == st_crs(DEM)

# NAD83 (epsg = 4269)
st_crs(DEM_NAD83) == st_crs(SFtracts_NAD83)
```

#################################

## About the `sp` package

As we mentioned in Part I, `sp` was for a long time the primary geospatial package in R.

`sf` has now eclipsed this package (along with the 'rgdal' and 'rgeos' packages).

However, as you can see, not all geospatial packages have made the transition already.

## `sp` package

You may sometimes run into issues such as the one we just experienced, where you can find an easy workaround.

Other times, however, you may actually need to work with `sp` objects instead of `sf` ones.

Luckily, this is easy!

## `sp` package

To convert __from `sf` to `sp`__, `sf` provides the `as_Spatial` function.

Let's convert `SFhomes15_sf`, then look at its string representation.

Note that it looks very similar to the metadata of a `raster` object.

```{r}
SFhomes15_sp <- as_Spatial(SFhomes15_NAD83)
SFhomes15_sp
```

## `sp` package

And look at its structure, which is also similar to that of the DEM raster.

```{r, eval=F}
str(SFhomes15_sp)
```

## `sp` package

That makes sense, because the `raster` and `sp` packages are designed to feel as
standardized and consistent as possible.

There _are_ differences, however!

Some are just stylistic:

- sp `@bbox` instead of raster `@extent`
- sp `@proj4string` instead of raster `@crs`

Some come from the difference between the vector and raster data models:

sp vector objects have
- no `dimensions` attribute
- no `resolution` (this _is_ a concept for vector data, but is not key metadata)
- a `@data` slot is a `data.frame` (a.k.a. an "attribute table")


## `sp` package

`sp` creates objects that pertain to any of a number of classes,
which conform to the `Spatial*DataFrame` convention:

- `SpatialPointsDataFrame`
- `SpatialLinesDataFrame`
- `SpatialPolygonsDataFrame`
- etc.

sp `Spatial` objects can then be transformed, subsetted, analyzed, and plotted,
using a variety of packages that may not be compatible (yet?) with `sf`.

Here's a plot:

```{r}
plot(SFhomes15_sp)
```

## `sp` package

And if you need to convert __from `sp` to `sf`__,
there's a function for that too (which we already saw in Part 1!).

```{r}
SFhomes15_sfagain <- st_as_sf(SFhomes15_sp)
plot(SFhomes15_sfagain$geometry)
plot(SFhomes15_sfagain['totvalue'])
```

## `sp` package

We will not go into any further detail on `sp` in this workshop.

However, if you find you need to learn more then please visit our
[former R geospatial workshop](https://github.com/dlab-geo/r-geospatial-workshop),
which is based on `sp`.

(It uses the same data and runs more or less the same operations as this workshop,
so the comparison with this workshop should highlight all the differences between `sf` and `sp`.)


## Cropping Rasters

Since the raster data covers a larger area than our vector data / area of interest,
we can **clip**, or **crop**, it using the `raster::crop` function.

```{r}
# clip the NAD83 CRS version of the rasters to SFtracts 
DEM_NAD83_crop <- crop(DEM_NAD83, SFtracts_NAD83)

# Clip the NAD27 CRS version
DEM_crop <- crop(DEM, SFtracts_NAD27)

```

## Plot Cropped Raster data

You can plot raster and vector
```{r}
plot(DEM_NAD83_crop)
```

## Plot Raster & Vector Data

Here we plot the NAD83 CRS version.
```{r, warning=F}
# plot together
plot(DEM_NAD83_crop)
plot(SFtracts_NAD83$geometry, add=T, border="black")
```

## Masking Raster Data

Notice that the clipping (or cropping) operation reduced our dataset to just the extent of the census-tract dataset.

But it still left us with values outside of the census tracts themselves (because they are areas outside the city of San Francisco, eg Marin & Tiburon).

## Masking Raster Data

For some purposes, we may want to get rid of those values as well. 

We can do this with an operation called **masking**.

```{r}
DEM_NAD83_crop_masked = mask(DEM_NAD83_crop, SFtracts_NAD83)
```

## Masking Raster Data

Here's what that gives us, compared to the unmasked object:

```{r}
# What's different?
DEM_NAD83_crop_masked
DEM_NAD83_crop
```

## Masking Raster Data

Still a rectangular grid of cells (because a raster will __always__ be rectangular).

Still has the same `nrow` and `ncol` as the unmasked object. 

What masking did was to set the cells that lie outside our dataset to `NAs`.


## Masking Raster Data

```{r}
plot(DEM_NAD83_crop_masked)
plot(st_geometry(SFtracts_NAD83), add = T, col = NA)
```

## Plotting rasters in `tmap`

We can make an interactive plot using `tmap`

```{r, message=F}
my_map <- tm_shape(DEM_NAD83_crop_masked) +
  tm_raster() +
tm_shape(SFtracts_NAD83) + 
  tm_borders()

# Set mode to interactive
tmap_mode("view")
```

## View Map
```{r}
my_map
```

## Writing Raster Data

And now that we've manipulated our data as desired, we can write it to disk
if we like!

```{r}
# write our reprojected, cropped data to the data directory, using the Geotiff format
# (and allow R to overwrite if file already exists)
writeRaster(DEM_NAD83_crop_masked, 
            filename = here("outdata",
                            "DEM_reproject_crop.tif"), 
            format = "GTiff",
            overwrite = T)
```



# Section 2: Raster Operations and Spatial Analysis

## Challenge section

This section will feature a number of challenges, to get you practicing some of the
material we've already covered today.

## Extract elevation values

We can use the `raster::extract` function to get the elevation values for each tract.

```{r}
# get the elevation for every cell in each of the census tracts
elev <- extract(DEM_NAD83_crop, SFtracts_NAD83)

#what did that give us?
head(elev)
tail(elev)
```

## What is the output?

Check out the data in the `elev` object
```{r}
length(elev)
nrow(SFtracts_NAD83)
```
It's a vector of the elevations for all the raster cells within each census tract!

Let's take a closer look
```{r}
# Large census tract at row 100
plot(SFtracts_NAD83$geometry)
plot(SFtracts_NAD83[100,]$geometry, add=T, col="red")

# Lots of cells
elev[100]
```

## Average Raster value by Vector shape

Let's get each tract's average elevation
```{r}
mean_elev = lapply(elev, mean, na.rm = T)
head(mean_elev)
mean_elev[100]

# Compare that to
mean(elev[100])

#oops - use unlist to flatten a list of vectors to a single vector
mean(unlist(elev[100]))
```

## Add elevation to Vector object

Let's add this to the SFtracts_NAD83 `data.frame`.

__Note__: Since the order remains the same, we can just add this right in!

```{r}
SFtracts_NAD83$mean_elev = unlist(mean_elev)
head(SFtracts_NAD83)
```

## Map it
```{r}
#what did we get?
elev_map <- tm_shape(SFtracts_NAD83) + 
  tm_polygons(col = 'mean_elev') +
  tm_layout("The pain of biking in SF, by census tract", 
            inner.margins = c(0, 0, 0.1, 0), 
            title.size = 4.8)

#display map
elev_map
```

## Map it


## One step Re-do

We can also pass a function argument to `raster::extract`
```{r}
elev <- extract(DEM_NAD83_crop, SFtracts_NAD83, fun=mean)

#what did that give us?
head(elev)
```

## Questions?

Do you see the difference between those two approaches?

1. Mapping a vector layer on top of a raster layer (i.e. `my_map`)

2. Summarizing raster values by vector polygons, then mapping the polygons (`elev_map`)

```{r, echo=F}
my_map + elev_map
```


## Challenge 2: Read in and check out new data

You have another raster dataset in your `./data` directory. The file is called
`nlcd2011_sf.tif`.

This is data from the [National Land Cover Database (NLCD)](https://www.mrlc.gov/nlcd11_leg.php).

It's 2011 data that was downloaded from [here](https://viewer.nationalmap.gov/basic).

Read that file in as an object called `nlcd`, and plot it.


## Solution

```{r}
# read in nlcd data


# plot nlcd

```

# Take a look at the raster metadata
```{r}
nlcd <- raster(here("notebook_data",
                    "part_3",
                    "nlcd2011_sf.tif"))
nlcd
```
## Let's see what's in the NLCD data

```{r}
freq(nlcd)
```

## ... and a barplot

(__Note__: The colors in this barplot have no relation to the colors in our maps!
Just pay attention to the categories on the x-axis.)

```{r}
barplot(nlcd)
```

## What do those values mean?

This is a categorical raster. Each cell on the raster holds a discrete (integer) value, coding a particular type of land-cover (rather than a continuous value, like we saw with our elevation data above).

Where do we do to figure out what the codes mean?
This should come with the metadarad that ships with your data,
or that is provided at the website where you downloaded it.

[Here](https://www.mrlc.gov/data/legends/national-land-cover-database-2011-nlcd2011-legend)'s the NLCD legend.


## Challenge 3: Reproject and crop our NLCD data

Now that we've read in our NCLD data, check if we need to reproject it (we want it to be in the same projection as our `SFtracts` object), and project it if need be.

Then crop it to the extent of our `SFtracts` object.

## Your Solution

```{r}
# check projection equality
st_crs(nlcd) == st_crs(SFtracts_WGS84)


#reproject
nlcd_WGS84 = projectRaster(nlcd, 
                         projectExtent(nlcd, st_crs(SFtracts_WGS84)$proj4string))

#check projection equality again
st_crs(nlcd_WGS84) ==  st_crs(SFtracts_WGS84)

#crop
nlcd_WGS84_crop = crop(nlcd_WGS84, SFtracts_WGS84)

```

## Plot the new raster

```{r}
plot(nlcd_WGS84_crop)
```

## Recovering our plot formatting

Notice that the colors of our original, which conveniently represented the NLCD class
colors from their website, are lost after reprojecting and cropping our raster.

Those colors were controlled by information in the original file,
which was read into the `@legend` slot. Here's the info (with hexadecimal format for color codes, e.g. '#00F900'):

```{r}
nlcd@legend
```

## Recover our plot formatting

What's the `@legend` slot in our reproject, cropped object look like?

```{r}
nlcd_WGS84_crop@legend
```

## Recover our plot formatting

Well that's a bummer...

Is there a way we could transfer that information over to our reprojected, cropped raster?

## Transferring our `@legend` info

Without looking ahead, think about how to transfer the `@legend` info from the original raster object to our new object. 


## Solution


```{r}
nlcd_WGS84_crop@legend = nlcd@legend
plot(nlcd_WGS84_crop)
```


## Aaalllmoost...

Looking good!

But what are all those funky-colored speckles?

Turns out that raster reprojection requires interpolation of values, in order
to bring one grid's values to another, unaligned grid's values.

By default, `raster` uses **bilinear interpolation** to do this. But this doesn't
make sense for categorical variables, because it returns non-sensical fractional
categorical values!

We can change this behavior by telling `raster::projectRaster` to use nearest-neighbor
interpolation instead. 

The `?projectRaster`documentation notes that this method is better suited
to categorical data.

So let's do that:

```{r}
#reproject again, this time using nearest-neighbor interpolation
nlcd_WGS84 <- projectRaster(nlcd, 
                          projectExtent(nlcd, 
                                        st_crs(SFtracts_WGS84)$proj4string),
                                        method = 'ngb') # Nearest neighbor

#check projection equality again
st_crs(nlcd_WGS84) == st_crs(SFtracts_WGS84)
#crop again
nlcd_WGS84_crop = crop(nlcd_WGS84, SFtracts_WGS84)
#grab our legend again
nlcd_WGS84_crop@legend = nlcd@legend

#plot to check again - dan, dan, dah!
plot(nlcd_WGS84_crop)
```

## Selecting Cells with Specific values
```{r}
# Take a look at just the nlcd cells coded developed, low density (22)
lowdens <- mask(nlcd, nlcd == 22, maskvalue=F)
freq(lowdens)
plot(lowdens)
```

## Changing Raster Values
```{r}
# Recode the values to 1
lowdens1 <- lowdens
lowdens1[lowdens == 22] <- 1
freq(lowdens1)
plot(lowdens1)
```

## Raster Math - Map Algebra
We can add, subtract, mult, divide, etc, raster of the same extent (CRS) and resolution.

Here is just a dummy example!
```{r}
lowdens2 <- lowdens1 + lowdens1
freq(lowdens2)
```

## Reclassifying rasters

When we're working with a categorical raster we'll often want to reclassify our data. We may want to do this because:

- Our original data has more classifications than we actually need for our analysis.
- We want to represent the classifications we do have by a different numerical scheme because it somehow makes our analysis more convenient.

## Reclass the NLCD

Let's reclass our NLCD data. First we'll need to define a reclassification
matrix with 3 columns (low, high, to):

```{r, eval = FALSE}
?reclassify
```

## Define reclassification matrix 
See https://www.mrlc.gov/data/legends/national-land-cover-database-2011-nlcd2011-legend
```{r}
#freq(nlcd) #to see all vals

# Note: by default, the ranges dont include left val, but include right
reclass_vec <- c(0, 20, NA, # water will be set to NA (i.e. 'left out' of our analysis)
                20, 21, 1,  # we'll treat developed open space as greenspace, 
                            #  based on the NLCD description
                21, 30, 0,  # developed and hardscape will be set to 0s
                30, 31, NA, 
                31, Inf, 1) # greenspace will have 1s

# take a look at the table 
reclass_vec 

# Create the reclass matrix
reclass_m <- matrix(reclass_vec, ncol = 3, byrow = TRUE)
reclass_m
```

## Reclassify the raster 
```{r}
nlcd_green <- reclassify(nlcd_WGS84_crop, reclass_m)
```

## Reclassify the raster

What did we get?

```{r}
freq(nlcd_green)
```

## Reclassify the raster 

What did we get?

```{r}
barplot(nlcd_green)
```

## Reclassify the raster 

What did we get?

```{r}
plot(nlcd_green)
```

## Challenge 4: Extract reclassed NLCD data to our tract polygons

Just like we did earlier with our elevation data, let's extract our reclassed
NLCD data to our census-tract polygons.

## Solution

```{r}

# extract the mean nlcd_simple values to tract polygons
#greenspace <- ...
```

## What did we get?

```{r, eval=F}
greenspace
```

## Why?

What's with all the NAs?

Remember, we set all water cells to NA, to ignore them in our analysis.

## How do we get extract to ignore our NAs?

Let's run the same command again, but telling the extract function to ignore NAs.

The `na.rm` argument will do this for us. See how the docs indicate that it is set to FALSE by default? 

```{r, eval = FALSE}
?raster::extract
```

Good to know!  Also good to know that this is a common
argument across a variety of R operations.

## Removing NAs in Calculations

```{r}
#extract the mean nlcd_simple values to tract polygons,
#this time setting na.rm to TRUE
greenspace <- extract(nlcd_green, SFtracts_WGS84, fun=mean, na.rm = T)

#and add to our SFtracts dataframe (which we can do because order is preserved)
SFtracts_WGS84$prop_greenspace = greenspace
```

## Get the mean home values in each tract

Pulling code from the end of Part II of this workshop, let's aggregate our homes data to the tract level too.

```{r}
#aggregate totvalue to SFtracts
SFtracts_w_mean_val <- aggregate(x = SFhomes15_WGS84['totvalue'],
                                 by = SFtracts_WGS84,
                                 FUN = mean)

#and add the totvalue column to our SFtracts dataframe
SFtracts_WGS84$mean_totvalue <- SFtracts_w_mean_val$totvalue
```

## Get the mean home values in each tract

Here we use the "quick tmap" function `qtm`.

```{r}
qtm(SFtracts_w_mean_val, fill = 'totvalue')
```

## Predicting home values

Do mean elevation and proportion greenspace predict mean home values?

(__Note__: This is not a statistically valid model! Just an example of a raster data analysis workflow.)

```{r}
mod <- lm(mean_totvalue ~ unlist(mean_elev) + prop_greenspace, data = SFtracts_WGS84)
summary(mod)
```

## Predicting home values

Not at the census-tract level. But that's kind of coarse...

What if we want to do the analysis at the property level?

We have added this workflow as an appendix in a separate document, 10_Raster_appendix.Rmd. It puts together a bunch of what we've learned over Parts I to III of the workshop. Feel free to give it try later!


## Questions?


# Section 3: RasterStacks and RasterBricks

## RasterStacks

A RasterStack is a collection of RasterLayer objects with the **same spatial extent and resolution**. 

A RasterStack can be created from RasterLayer objects, or from multiple raster files.

```{r}
#?raster::stack

# Create a stack from 2 rasters
DEMx2 <- stack(DEM_NAD83_crop, DEM_NAD83_crop_masked)
DEMx2

# Plot the stack
plot(DEMx2)

# Plot one layer in the stack
plot(DEMx2[[1]])

# Does this work?
#demNelev <- stack(DEM_NAD83_crop, nlcd_WGS84_crop)
```

## RasterBrick

A RasterBrick is a multi-layer raster object that is created from a single file or raster stack.

Raster computations on a brick are faster than on a raster stack! 

```{r}
#?raster::brick

# Creating a brick from a stack
DEMx2brick <- brick(DEMx2)
# or
#DEMx2brick <- brick(DEM_NAD83_crop, DEM_NAD83_crop_masked)

#Take a look
DEMx2brick

# Summary stats
summary(DEMx2brick)

# Plotting
plot(DEMx2brick)
plot(DEMx2brick[[1]])
```

## Raster Algebra

Calculations across raster layers

```{r}
# Mean values
mean_dem <- mean(DEMx2brick)
hist(mean_dem)

```

## Raster Algebra - thought exercise.

Where to start my SF apartment hunting?

My evaluative criteria?

- Land cover class is low-med intensity
- Elevation is high, I want a view

Approach? Let's discuss

```{r}
# Psuedo code as comments



```


## Questions?

## Additional Resources

- [Geocomputation in R](https://geocompr.robinlovelace.net/index.html) - THE book on working with geospatial data in R. Raster sections feature the new+fabulous `terra` package.

- The [`raster` package vignettes](https://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf)
 - A [National Ecological Observatory Network tutorial](https://www.neonscience.org/raster-data-r)
- A [National Center for Ecological Analysis and Synthesis tutorial](https://nceas.github.io/oss-lessons/spatial-data-gis-law/4-tues-spatial-analysis-in-r.html)
- A [Waginingen University & Research tutorial](https://geoscripting-wur.github.io/IntroToRaster/)
- A [really well organized, intro raster tutorial by Dr. Emily Burchfield](https://www.emilyburchfield.org/courses/gsa/6_rasters_lab.html)

---

